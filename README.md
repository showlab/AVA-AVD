## This is the official repo copy for AVA-AVD dataset and AVR-Net model.
You can refer to the [original repo](https://github.com/zcxu-eric/AVA-AVD) for issues.
Preprints: [AVA-AVD: Audio-visual Speaker Diarization in the Wild](https://arxiv.org/abs/2111.14448)
### Dependencies

Build the environment:
```
sudo apt-get install ffmpeg
pip install -r requirement.txt
```

***
### Data preparation
[AVA-AVD Dataset](https://github.com/zcxu-eric/AVA-AVD/tree/main/dataset)

### Training and inference
[AVR-Net codebase](https://github.com/zcxu-eric/AVA-AVD/tree/main/model)

Please kindly cite our paper if you find this repo useful:
```
@inproceedings{xu2022ava,
author = {Xu, Eric Zhongcong and Song, Zeyang and Tsutsui, Satoshi and Feng, Chao and Ye, Mang and Shou, Mike Zheng},
title = {AVA-AVD: Audio-Visual Speaker Diarization in the Wild},
year = {2022},
pages = {3838â€“3847},
location = {Lisboa, Portugal},
series = {MM '22}
}
```
